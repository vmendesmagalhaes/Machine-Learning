{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vmendesmagalhaes/machine-learning/blob/main/Prediction_of_the_moisture_content_variation_on_wood.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-10UdlcZ2sc"
      },
      "source": [
        "# Prediction of the moisture content variation on wood\n",
        "\n",
        "**Author:** Vitor Mendes Magalhaes\n",
        "\n",
        "**Email:** vitor.mendes.magalhaes@gmail.com\n",
        "\n",
        "**Last review:** Mar/2023"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fltjEcPTtOMq"
      },
      "source": [
        "Wood is the raw material for many manufactured goods. Charcoal, cellulose for the paper industry, laminated wood furniture, and even explosive products, such as gunpowder cotton, are possible destinations for the wood. On the other hand, the growing use of wood as a raw material has increased illegal deforestation and, as a direct consequence, it has changed the climate at a global level.\n",
        "\n",
        "Regardless of the destination that will be given to the wood logs, many products that have wood as raw material go through the same stage: the storage of logs in piles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZfvFULttbI2"
      },
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1cvJZKoJ-6OyJ74RzLriWSX6rShB2wi5N)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6k1KTRedtZId"
      },
      "source": [
        "But as the storage time on piles passes, the moisture content on wood will reduce.\n",
        "\n",
        "The use of wood in production processes must be optimized to mitigate these adverse effects. One of the determining factors for this optimization is moisture content on wood, i.e., the ratio between the mass of water contained in the wood and dry wood mass.\n",
        "\n",
        "Here, we develop a Artificial Intelligence-based model - specifically using machine learning classification and regression methods - to predict the moisture content on wood, contributing to a better use of the wood in industry.\n",
        "\n",
        "Let's start by loading the necessary libraries for solving the present applied research problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0A8j7EeWB75"
      },
      "outputs": [],
      "source": [
        "import pandas as pandas\n",
        "import numpy as numpy\n",
        "from numpy import absolute\n",
        "from numpy import std\n",
        "from numpy import mean\n",
        "import matplotlib.pyplot as matplot\n",
        "import seaborn as seaborn\n",
        "from sklearn.model_selection import train_test_split as createDataPartition\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import random\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from scipy.stats import friedmanchisquare\n",
        "\n",
        "!pip install scikit-posthocs\n",
        "import scikit_posthocs as sp\n",
        "\n",
        "import itertools\n",
        "\n",
        "#!pip install pingouin\n",
        "#from pingouin import pairwise_ttests, add_custom_posthoc\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First of all, we need to ensure the reproducibility of the experiment. Let's do this by setting a seed."
      ],
      "metadata": {
        "id": "iQDxJ69_3SjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(7)"
      ],
      "metadata": {
        "id": "5F-SBrL54HKS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkYihumGjWdD"
      },
      "source": [
        "The next step is importing the spreadsheet (.XLS file) containing the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SbTwRtmBo9Qo"
      },
      "outputs": [],
      "source": [
        "dados = pandas.read_excel('datasetjan23.xls')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyrokgrApkA3"
      },
      "source": [
        "Now we have the data, let's start working on it.\n",
        "\n",
        "First, let's create a new attribute, called *PERCENTUAL*. It means the percentage of weight loss in relation to the total amount of incoming wood logs in each pile."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bHyUJDmopxo-"
      },
      "outputs": [],
      "source": [
        "dados['PERCENTUAL'] = (dados['ESTORNO'] * 100) / dados['TOT_ENTR']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNpS1ChEr1SV"
      },
      "source": [
        "After creating the new attribute, we will remove the instances of piles that didn't have log outputs (in theory, if they do not represent an operational error, these piles continued to receive loads of wood, or were not yet closed, at the time of data capture).\n",
        "\n",
        "We will also remove instances of piles that have not had reversed charges, that is, that in theory there was no loss of moisture. In the case of wood logs stored outdoors (technically, it is called \"natural drying\"), under the conditions of the captured data, there will always be moisture loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uIiqzQgCr8ug"
      },
      "outputs": [],
      "source": [
        "dados.drop(dados[dados['TOT_SAID'] == 0].index, inplace=True)\n",
        "dados.drop(dados[dados['ESTORNO'] == 0].index, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDiAvLNw39VX"
      },
      "source": [
        "After removing the instances, let's create a copy of the original dataset, which will be used to train different problem solving models using supervised learning. We will train classification models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hIL7O7x74Sqj"
      },
      "outputs": [],
      "source": [
        "dfClassificacao = dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9w4ZJM9v4Xgb"
      },
      "source": [
        "Now, let's start the pre-processing step, removing the attributes that are not interesting for creating the learning models to be applied.\n",
        "\n",
        "Once this is done, we will continue pre-processing the data, now with a selection of features, removing attributes and biasing the data to conform to the type of supervised learning they propose."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XN6RdFXO5bu5"
      },
      "source": [
        "For the development of the classification models, let's create a new attribute, called *INTERVALOPERDA*, meaning the loss ranges. Loss ranges are nothing more than weight loss percentage ranges, eg between 0% and 5% loss; between 5% and 10% loss, and so on, as far as the data allows.\n",
        "\n",
        "To define the best weight loss percentage ranges, we will first analyze visually, using three different visual analysis tools: a *boxplot*, a summary of the *PERCENTUAL* attribute (which will dictate the ranges), and a histogram with the frequency of instances with different percentages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "SvRSax9A52bY",
        "outputId": "cb43feb0-99e3-427c-b089-fe46fbd35c2e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "dfClassificacao.boxplot(column =['PERCENTUAL'], grid = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "BQWEh4K87S_Y",
        "outputId": "1a9873bd-8391-4cdb-fc50-c01bc5ca5baf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "dfClassificacao['PERCENTUAL'].hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "r-PxLgr79Aug",
        "outputId": "ca0e2f00-5621-45b8-ad09-35d5ea3c0bd9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            PILHA  COMPRIMENTO    TEMP_MIN    TEMP_MAX    TEMP_MED  \\\n",
              "count  502.000000   502.000000  502.000000  502.000000  502.000000   \n",
              "mean   380.834661     5.191633    6.353386   30.933068   17.668108   \n",
              "std    201.004887     0.380277    4.468436    6.301451    3.514570   \n",
              "min      1.000000     3.900000    1.900000   18.100000   11.640000   \n",
              "25%    209.250000     5.200000    3.300000   26.700000   14.965000   \n",
              "50%    381.500000     5.200000    5.400000   32.500000   17.395000   \n",
              "75%    556.750000     5.200000    8.600000   34.400000   20.377500   \n",
              "max    722.000000     6.000000   24.000000   39.400000   26.930000   \n",
              "\n",
              "          TEMP_PO  PRECIPITACAO     PATM_MED      UR_MIN      UR_MED  \\\n",
              "count  502.000000    502.000000   502.000000  502.000000  502.000000   \n",
              "mean    13.021813    230.048207  1015.596673   29.844622   75.807032   \n",
              "std      2.811104    204.907322     2.839966    9.870406    4.102414   \n",
              "min      6.380000      0.000000  1005.890000   21.000000   64.360000   \n",
              "25%     11.017500     41.400000  1013.885000   21.000000   71.902500   \n",
              "50%     12.805000    184.300000  1016.310000   26.000000   76.105000   \n",
              "75%     14.797500    392.200000  1016.920000   36.000000   79.260000   \n",
              "max     23.340000   1156.000000  1026.700000   70.000000   84.670000   \n",
              "\n",
              "        VENTO_MED  RAJ_MAX_MED    QTD_DIAS      TOT_ENTR      TOT_SAID  \\\n",
              "count  502.000000   502.000000  502.000000  5.020000e+02  5.020000e+02   \n",
              "mean     3.020159    10.148426   82.864542  2.955402e+05  2.608087e+05   \n",
              "std      0.423014     1.044224   70.283867  4.209043e+05  3.530809e+05   \n",
              "min      1.430000     5.700000    0.000000  1.144000e+04  3.030000e+03   \n",
              "25%      2.700000     9.480000   22.000000  1.312050e+05  1.127950e+05   \n",
              "50%      3.155000    10.440000   69.000000  2.329100e+05  2.047900e+05   \n",
              "75%      3.260000    10.660000  133.750000  3.658750e+05  3.268445e+05   \n",
              "max      4.630000    14.300000  425.000000  8.128820e+06  6.628260e+06   \n",
              "\n",
              "          DIFERENCA       ESTORNO  PERCENTUAL  \n",
              "count  5.020000e+02  5.020000e+02  502.000000  \n",
              "mean   3.473146e+04  3.217752e+04   11.404791  \n",
              "std    8.307838e+04  7.519074e+04   11.723297  \n",
              "min   -1.996000e+04  2.000000e+01    0.005657  \n",
              "25%    6.310000e+03  6.310000e+03    3.414372  \n",
              "50%    1.883000e+04  1.746000e+04    8.179170  \n",
              "75%    3.958000e+04  3.842550e+04   15.792322  \n",
              "max    1.500560e+06  1.500560e+06   91.583333  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8f8a4509-4e94-40a7-86fc-924c0495dde3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PILHA</th>\n",
              "      <th>COMPRIMENTO</th>\n",
              "      <th>TEMP_MIN</th>\n",
              "      <th>TEMP_MAX</th>\n",
              "      <th>TEMP_MED</th>\n",
              "      <th>TEMP_PO</th>\n",
              "      <th>PRECIPITACAO</th>\n",
              "      <th>PATM_MED</th>\n",
              "      <th>UR_MIN</th>\n",
              "      <th>UR_MED</th>\n",
              "      <th>VENTO_MED</th>\n",
              "      <th>RAJ_MAX_MED</th>\n",
              "      <th>QTD_DIAS</th>\n",
              "      <th>TOT_ENTR</th>\n",
              "      <th>TOT_SAID</th>\n",
              "      <th>DIFERENCA</th>\n",
              "      <th>ESTORNO</th>\n",
              "      <th>PERCENTUAL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>502.000000</td>\n",
              "      <td>502.000000</td>\n",
              "      <td>502.000000</td>\n",
              "      <td>502.000000</td>\n",
              "      <td>502.000000</td>\n",
              "      <td>502.000000</td>\n",
              "      <td>502.000000</td>\n",
              "      <td>502.000000</td>\n",
              "      <td>502.000000</td>\n",
              "      <td>502.000000</td>\n",
              "      <td>502.000000</td>\n",
              "      <td>502.000000</td>\n",
              "      <td>502.000000</td>\n",
              "      <td>5.020000e+02</td>\n",
              "      <td>5.020000e+02</td>\n",
              "      <td>5.020000e+02</td>\n",
              "      <td>5.020000e+02</td>\n",
              "      <td>502.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>380.834661</td>\n",
              "      <td>5.191633</td>\n",
              "      <td>6.353386</td>\n",
              "      <td>30.933068</td>\n",
              "      <td>17.668108</td>\n",
              "      <td>13.021813</td>\n",
              "      <td>230.048207</td>\n",
              "      <td>1015.596673</td>\n",
              "      <td>29.844622</td>\n",
              "      <td>75.807032</td>\n",
              "      <td>3.020159</td>\n",
              "      <td>10.148426</td>\n",
              "      <td>82.864542</td>\n",
              "      <td>2.955402e+05</td>\n",
              "      <td>2.608087e+05</td>\n",
              "      <td>3.473146e+04</td>\n",
              "      <td>3.217752e+04</td>\n",
              "      <td>11.404791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>201.004887</td>\n",
              "      <td>0.380277</td>\n",
              "      <td>4.468436</td>\n",
              "      <td>6.301451</td>\n",
              "      <td>3.514570</td>\n",
              "      <td>2.811104</td>\n",
              "      <td>204.907322</td>\n",
              "      <td>2.839966</td>\n",
              "      <td>9.870406</td>\n",
              "      <td>4.102414</td>\n",
              "      <td>0.423014</td>\n",
              "      <td>1.044224</td>\n",
              "      <td>70.283867</td>\n",
              "      <td>4.209043e+05</td>\n",
              "      <td>3.530809e+05</td>\n",
              "      <td>8.307838e+04</td>\n",
              "      <td>7.519074e+04</td>\n",
              "      <td>11.723297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.900000</td>\n",
              "      <td>1.900000</td>\n",
              "      <td>18.100000</td>\n",
              "      <td>11.640000</td>\n",
              "      <td>6.380000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1005.890000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>64.360000</td>\n",
              "      <td>1.430000</td>\n",
              "      <td>5.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.144000e+04</td>\n",
              "      <td>3.030000e+03</td>\n",
              "      <td>-1.996000e+04</td>\n",
              "      <td>2.000000e+01</td>\n",
              "      <td>0.005657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>209.250000</td>\n",
              "      <td>5.200000</td>\n",
              "      <td>3.300000</td>\n",
              "      <td>26.700000</td>\n",
              "      <td>14.965000</td>\n",
              "      <td>11.017500</td>\n",
              "      <td>41.400000</td>\n",
              "      <td>1013.885000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>71.902500</td>\n",
              "      <td>2.700000</td>\n",
              "      <td>9.480000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>1.312050e+05</td>\n",
              "      <td>1.127950e+05</td>\n",
              "      <td>6.310000e+03</td>\n",
              "      <td>6.310000e+03</td>\n",
              "      <td>3.414372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>381.500000</td>\n",
              "      <td>5.200000</td>\n",
              "      <td>5.400000</td>\n",
              "      <td>32.500000</td>\n",
              "      <td>17.395000</td>\n",
              "      <td>12.805000</td>\n",
              "      <td>184.300000</td>\n",
              "      <td>1016.310000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>76.105000</td>\n",
              "      <td>3.155000</td>\n",
              "      <td>10.440000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>2.329100e+05</td>\n",
              "      <td>2.047900e+05</td>\n",
              "      <td>1.883000e+04</td>\n",
              "      <td>1.746000e+04</td>\n",
              "      <td>8.179170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>556.750000</td>\n",
              "      <td>5.200000</td>\n",
              "      <td>8.600000</td>\n",
              "      <td>34.400000</td>\n",
              "      <td>20.377500</td>\n",
              "      <td>14.797500</td>\n",
              "      <td>392.200000</td>\n",
              "      <td>1016.920000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>79.260000</td>\n",
              "      <td>3.260000</td>\n",
              "      <td>10.660000</td>\n",
              "      <td>133.750000</td>\n",
              "      <td>3.658750e+05</td>\n",
              "      <td>3.268445e+05</td>\n",
              "      <td>3.958000e+04</td>\n",
              "      <td>3.842550e+04</td>\n",
              "      <td>15.792322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>722.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>39.400000</td>\n",
              "      <td>26.930000</td>\n",
              "      <td>23.340000</td>\n",
              "      <td>1156.000000</td>\n",
              "      <td>1026.700000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>84.670000</td>\n",
              "      <td>4.630000</td>\n",
              "      <td>14.300000</td>\n",
              "      <td>425.000000</td>\n",
              "      <td>8.128820e+06</td>\n",
              "      <td>6.628260e+06</td>\n",
              "      <td>1.500560e+06</td>\n",
              "      <td>1.500560e+06</td>\n",
              "      <td>91.583333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f8a4509-4e94-40a7-86fc-924c0495dde3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8f8a4509-4e94-40a7-86fc-924c0495dde3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8f8a4509-4e94-40a7-86fc-924c0495dde3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "dfClassificacao.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3dSCowT9S74"
      },
      "source": [
        "In a brief analysis, it is noticed that there are possible operational errors that can generate noise in the classification model, allowing them to be considered outliers.\n",
        "\n",
        "A clear example is the loss percentage. There are percentages that tend to 100%, which does not occur in this process; there are also percentages that tend to 0% - same situation.\n",
        "\n",
        "So let's remove the instances with losses above 40%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eVxEJTPL9zoL"
      },
      "outputs": [],
      "source": [
        "dfClassificacao = dfClassificacao.drop(dfClassificacao[dados['PERCENTUAL'] >= 40].index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpxYef71-EaQ"
      },
      "source": [
        "Afterwards, let's check again through the *boxplot*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "ETCKYU_c-J9j",
        "outputId": "517daef2-4c80-443d-eaba-476155909400"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "dfClassificacao.boxplot(column =['PERCENTUAL'], grid = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMoSmpiQ-Xwc"
      },
      "source": [
        "Now we can return to the creation of the attribute *INTERVALOPERDA*, establishing different intervals of loss percentages:\n",
        "\n",
        "CLASS | INTERVAL\n",
        "--- | ---\n",
        "1 | less than 10%\n",
        "2 | between 10% and 20%\n",
        "3 | between 20% and 30%\n",
        "4 | more than 30%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1_scqdvP_rZP"
      },
      "outputs": [],
      "source": [
        "for i, linha in dfClassificacao.iterrows():\n",
        "  if (linha['PERCENTUAL'] <= 10):\n",
        "    dfClassificacao.loc[i, 'INTERVALOPERDA'] = 1;\n",
        "  elif ((linha['PERCENTUAL'] > 10) and (linha['PERCENTUAL'] <= 20)):\n",
        "    dfClassificacao.loc[i, 'INTERVALOPERDA'] = 2;\n",
        "  elif ((linha['PERCENTUAL'] > 20) and (linha['PERCENTUAL'] <= 30)):\n",
        "    dfClassificacao.loc[i, 'INTERVALOPERDA'] = 3;\n",
        "  else:\n",
        "    dfClassificacao.loc[i, 'INTERVALOPERDA'] = 4;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJo0hEjXUU3u"
      },
      "source": [
        "Once the *INTERVALOPERDA* attribute is created, let's remove the attributes that will not be important for the creation of the learning models - more specifically, the classification.\n",
        "\n",
        "In this sense, we will remove the stack identification (*PILHA*), the dates (*DATA_INICIO* and *DATA_FIM*, the output weight (*TOT_SAID*), the difference between the input and output totals (*DIFERENCA*) , the amount reversed (*ESTORNO*) and the percentage (*PERCENTUAL*).\n",
        "\n",
        "Thus, we make it clear that the class we want to predict is the *INTERVALOPERDA*, just created, which contains the interval (in percentage) of wood weight loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ln9OmaUNUyfG"
      },
      "outputs": [],
      "source": [
        "dfClassificacao = dfClassificacao.drop([\"PILHA\", \"DATA_INICIO\", \"DATA_FIM\", \"TOT_SAID\", \"DIFERENCA\", \"ESTORNO\", \"PERCENTUAL\"], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDWfMrp2pE2-"
      },
      "source": [
        "After creating the attribute (class) that will be our target, and removing the attributes that will not be predictors of our models, we will check the balance of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHOCrgJPpllu",
        "outputId": "2889b43c-7ddf-4e32-a809-42fcd35bac27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0    288\n",
            "2.0    142\n",
            "3.0     43\n",
            "4.0     14\n",
            "Name: INTERVALOPERDA, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(dfClassificacao['INTERVALOPERDA'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMzbjanopy55"
      },
      "source": [
        "We can clearly observe that the largest number of instances is represented in classes 1 and 2, that is, the vast majority of the piles present in the dataset have a weight loss (due to the loss of moisture content) of less than 20%.\n",
        "\n",
        "We will verify the integrity of these data, analyzing the moisture losses from the piles in relation to the number of days that the logs remained stored (in the same piles)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7X6S35iqHZu",
        "outputId": "518b6a54-dbb6-4c21-da78-f491397d57d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    487.000000\n",
            "mean      81.266940\n",
            "std       68.858645\n",
            "min        0.000000\n",
            "25%       22.000000\n",
            "50%       68.000000\n",
            "75%      127.000000\n",
            "max      425.000000\n",
            "Name: QTD_DIAS, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(dfClassificacao['QTD_DIAS'].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qZGUL4sqaNr"
      },
      "source": [
        "Considering, then, that when it comes to loss of moisture content in wood stored outdoors (*natural drying*) 20% is a small percentage, it can be easily inferred that these logs, due to the large number of days average battery life (81 days), had already been cut longer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQrV5sGVIY5k"
      },
      "source": [
        "As there are non-numeric predictor attributes, we need to treat them, transforming them into numerical attributes so that we can proceed with the training of the learning models (in Weka, in R and in other environments/languages, this transformation is not necessary, but it is need to analyze possible differences in the prediction result).\n",
        "\n",
        "Let's do the *one-hot-encoding* for categorical attributes that don't have any need for sorting, like product, bark, and species."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ybIpFNznJGrp"
      },
      "outputs": [],
      "source": [
        "atributos_a_codificar = ['PRODUTO', 'CASCA', 'ESPECIE', 'DIAMETRO']\n",
        "\n",
        "atributos_codificados = pandas.get_dummies(dfClassificacao[atributos_a_codificar])\n",
        "\n",
        "dfClassificacao = dfClassificacao.drop(atributos_a_codificar, axis=1).join(atributos_codificados)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEEosQa6lmsP"
      },
      "source": [
        "Before the next step, it's time to remove the class (*INTERVALOPERDA* attritube) and prepare the dataset to be splitted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "V5ApgvegFr4g"
      },
      "outputs": [],
      "source": [
        "dfClassificacaoTrain = dfClassificacao.drop([\"INTERVALOPERDA\"], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZXhmAHDWgjO"
      },
      "source": [
        "The dataset has not yet been partitioned. The tendency is for the partitions to reproduce the general behavior of the dataset. So let's split it before going ahead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_KD4JvGPqk-s"
      },
      "outputs": [],
      "source": [
        "dados_treino, dados_teste, classe_treino, classe_teste = createDataPartition(dfClassificacaoTrain, dfClassificacao['INTERVALOPERDA'], test_size=0.3, random_state=7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLHaGszRto8n"
      },
      "source": [
        "Thus, with the dataset partitioned with 75% of the data separated for training, and 25% for testing, we can proceed with the training of the models, with the data already biased towards supervised learning - classification.\n",
        "\n",
        "(we setted a seed to ensure te reprodutibility of the experiment)\n",
        "\n",
        "Let's then instantiate the classification models using some algorithms. We will use *Random Forest* (RF), *Logistic Regression* (LR), *Support Vector Machines* (SVM), *Gaussian Naive Bayes* (NB), *AdaBoost* (AB), *Gradient Boost* (GB) and *Multi-Layer Perceptrons* (ANN)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8WDlsvYauHDM"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier()\n",
        "lr = LogisticRegression()\n",
        "csvm = svm.LinearSVC()\n",
        "nb = GaussianNB()\n",
        "ab = AdaBoostClassifier()\n",
        "gb = GradientBoostingClassifier()\n",
        "mlp = MLPClassifier()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMALP5sEp3L_"
      },
      "source": [
        "Once the models are instantiated, it is time to train the classification models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bwCUeJ-uTOb"
      },
      "outputs": [],
      "source": [
        "rf.fit(dados_treino, classe_treino)\n",
        "lr.fit(dados_treino, classe_treino)\n",
        "csvm.fit(dados_treino, classe_treino)\n",
        "nb.fit(dados_treino, classe_treino)\n",
        "ab.fit(dados_treino, classe_treino)\n",
        "gb.fit(dados_treino, classe_treino)\n",
        "mlp.fit(dados_treino, classe_treino)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G50JebvqEJo"
      },
      "source": [
        "Once the models are trained (using both the training data and the training class), the next step is to verify the predictions, that is, what in fact the created models were able to learn from the available data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "I2ww95NPjJa9"
      },
      "outputs": [],
      "source": [
        "predicoes_rf = rf.predict(dados_teste)\n",
        "predicoes_lr = lr.predict(dados_teste)\n",
        "predicoes_svm = csvm.predict(dados_teste)\n",
        "predicoes_nb = nb.predict(dados_teste)\n",
        "predicoes_ab = ab.predict(dados_teste)\n",
        "predicoes_gb = gb.predict(dados_teste)\n",
        "predicoes_mlp = mlp.predict(dados_teste)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Txiint5_qXso"
      },
      "source": [
        "Keeping the predictions in a variable, we will check through a confusion matrix the results of the learning models predictions using classification with RF, LR, SVM, NB, AB, GB and ANN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSuYLsagqiKy",
        "outputId": "464389f1-c5a1-49c1-f0e8-abdaba4b61e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix of RF: \n",
            " [[75 10  1  0]\n",
            " [20 22  2  0]\n",
            " [ 4  8  1  0]\n",
            " [ 1  2  1  0]]\n",
            "Confusion matrix of LR: \n",
            " [[76 10  0  0]\n",
            " [24 20  0  0]\n",
            " [ 5  8  0  0]\n",
            " [ 1  3  0  0]]\n",
            "Confusion matrix of SVM: \n",
            " [[ 4 36  5 41]\n",
            " [ 2 33  2  7]\n",
            " [ 0  9  0  4]\n",
            " [ 0  3  0  1]]\n",
            "Confusion matrix of Gaussian Naive Bayes: \n",
            " [[78  1  7  0]\n",
            " [26  4 14  0]\n",
            " [ 5  2  6  0]\n",
            " [ 1  0  3  0]]\n",
            "Confusion matrix of AdaBoost: \n",
            " [[72  5  4  5]\n",
            " [19 21  3  1]\n",
            " [ 3  8  1  1]\n",
            " [ 1  0  1  2]]\n",
            "Confusion matrix of GradientBoost: \n",
            " [[72  9  2  3]\n",
            " [20 23  1  0]\n",
            " [ 4  6  2  1]\n",
            " [ 1  2  1  0]]\n",
            "Confusion matrix of MLP: \n",
            " [[85  1  0  0]\n",
            " [44  0  0  0]\n",
            " [13  0  0  0]\n",
            " [ 4  0  0  0]]\n"
          ]
        }
      ],
      "source": [
        "cm_rf = confusion_matrix(classe_teste, predicoes_rf)\n",
        "cm_lr = confusion_matrix(classe_teste, predicoes_lr)\n",
        "cm_svm = confusion_matrix(classe_teste, predicoes_svm)\n",
        "cm_nb = confusion_matrix(classe_teste, predicoes_nb)\n",
        "cm_ab = confusion_matrix(classe_teste, predicoes_ab)\n",
        "cm_gb = confusion_matrix(classe_teste, predicoes_gb)\n",
        "cm_mlp = confusion_matrix(classe_teste, predicoes_mlp)\n",
        "\n",
        "print(\"Confusion matrix of RF: \\n\", cm_rf)\n",
        "print(\"Confusion matrix of LR: \\n\", cm_lr)\n",
        "print(\"Confusion matrix of SVM: \\n\", cm_svm)\n",
        "print(\"Confusion matrix of Gaussian Naive Bayes: \\n\", cm_nb)\n",
        "print(\"Confusion matrix of AdaBoost: \\n\", cm_ab)\n",
        "print(\"Confusion matrix of GradientBoost: \\n\", cm_gb)\n",
        "print(\"Confusion matrix of MLP: \\n\", cm_mlp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wp0Br_bxqphs"
      },
      "source": [
        "Observing the confusion matrixes above, we can notice that our models are not good. Before the next step, we need to make the information clearer.\n",
        "\n",
        "For this, we are going to use some metrics, starting with the accuracy of the models. Accuracy can be described as how much, in percentage, the models are able to hit its predictions (always based on the data that the model had at its disposal)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXnGx-baqmpG",
        "outputId": "a3d479a3-0b58-43b7-b6f1-debf6cbbce7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RF accuracy: 0.6530612244897959\n",
            "LR accuracy: 0.6530612244897959\n",
            "SVM accuracy: 0.14285714285714285\n",
            "Naive Bayes accuracy: 0.5986394557823129\n",
            "AdaBoost accuracy: 0.6530612244897959\n",
            "GradientBoost accuracy: 0.6530612244897959\n",
            "MLP accuracy: 0.29931972789115646\n"
          ]
        }
      ],
      "source": [
        "print(\"RF accuracy:\", metrics.accuracy_score(classe_teste, predicoes_rf))\n",
        "print(\"LR accuracy:\", metrics.accuracy_score(classe_teste, predicoes_lr))\n",
        "print(\"SVM accuracy:\", metrics.accuracy_score(classe_teste, predicoes_svm))\n",
        "print(\"Naive Bayes accuracy:\", metrics.accuracy_score(classe_teste, predicoes_nb))\n",
        "print(\"AdaBoost accuracy:\", metrics.accuracy_score(classe_teste, predicoes_ab))\n",
        "print(\"GradientBoost accuracy:\", metrics.accuracy_score(classe_teste, predicoes_gb))\n",
        "print(\"MLP accuracy:\", metrics.accuracy_score(classe_teste, predicoes_mlp))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9vOjejZsfXz"
      },
      "source": [
        "It is important to keep in mind that, although accuracy is the proportion of correct predictions in relation to the total number of predictions, it is a simple metric, that is, it may not always be the most suitable metric - especially in unbalanced datasets (like this one)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gapZ771vZUO5"
      },
      "source": [
        "It's time to take a look at the classifiers, trying to tune the hyperparamethers and improve the performance of the developed models. Tuning hyperparameters is an important step to increase the efficiency of the model.\n",
        "\n",
        "We will use the *GridCV* to search exhaustively over some parameters to (and) get the best possible tune for each one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dd5fqINfcSIK"
      },
      "outputs": [],
      "source": [
        "#GridCV do RandomForest\n",
        "gridCV_rf = {\n",
        "  \t'n_estimators': [5, 10, 20, 50, 100],\n",
        "\t\t'max_features': ['sqrt', 'log2'],\n",
        "\t\t'max_depth': [5, 10, 15],\n",
        "\t\t'max_leaf_nodes': [3, 9, 15]\n",
        "}\n",
        "\n",
        "#GridCV do Logistic Regression\n",
        "gridCV_lr = {\n",
        "\t\t'C': [0.1, 1, 10, 100],\n",
        "\t\t'max_iter': [100, 1000, 100000],\n",
        "\t\t'multi_class': ['auto', 'ovr', 'multinomial']\n",
        "}\n",
        "\n",
        "#GridCV do SVM\n",
        "gridCV_svm = {\n",
        "\t\t'C': [0.1, 1, 10, 100, 1000],\n",
        "\t\t'max_iter': [10000, 100000, 500000]\n",
        "}\n",
        "\n",
        "#GridCV do Naive Bayes\n",
        "gridCV_naivebyes = {\n",
        "\t\t'var_smoothing': numpy.logspace(0,-9, num=100)\n",
        "}\n",
        "\n",
        "#GridCV do AdaBoost\n",
        "gridCV_adaboost = {\n",
        "  \t'n_estimators': [1, 10, 100, 200],\n",
        "\t\t'algorithm': ['SAMME', 'SAMME.R']\n",
        "}\n",
        "\n",
        "#GridCV do GradientBoost\n",
        "gridCV_gradientboost = {\n",
        "  \t'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.5, 1],\n",
        "\t\t'max_depth': [5, 6, 7, 8],\n",
        "\t\t'n_estimators': [1, 10, 100, 200]\n",
        "}\n",
        "\n",
        "#GridCV do MLP\n",
        "gridCV_MLP = {\n",
        "\t\t'max_iter': [100, 1000, 10000, 100000],\n",
        "  \t'hidden_layer_sizes': [(150, 100, 50), (40, 80, 120), (100, 150, 30), (30, 100, 50, 10)],\n",
        "    'activation': ['tanh', 'relu', 'logistic'],\n",
        "    'solver': ['sgd', 'adam', 'lbfgs'],\n",
        "    'learning_rate': ['constant','adaptive']\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pp2yaZwAi64w"
      },
      "source": [
        "We setted some possible hyperparamethers values, respecting the difference between the different models, and now we will search for the best tuning for the hyperparamethers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oGY9NGqdECy",
        "outputId": "7e1b3dcb-ac50-4eb0-b81e-4d1f508b9d56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_depth=5, max_features='log2', max_leaf_nodes=9,\n",
            "                       n_estimators=5)\n",
            "LogisticRegression(C=0.1, max_iter=100000)\n",
            "LinearSVC(C=100, max_iter=100000)\n",
            "GaussianNB(var_smoothing=8.111308307896856e-09)\n",
            "AdaBoostClassifier(algorithm='SAMME', n_estimators=1)\n",
            "GradientBoostingClassifier(learning_rate=0.01, max_depth=5, n_estimators=200)\n",
            "MLPClassifier(activation='tanh', hidden_layer_sizes=(100, 150, 30),\n",
            "              learning_rate='adaptive', max_iter=100000, solver='lbfgs')\n"
          ]
        }
      ],
      "source": [
        "grid_rf = GridSearchCV(rf, param_grid=gridCV_rf, cv=5)\n",
        "grid_lr = GridSearchCV(lr, param_grid=gridCV_lr, cv=5)\n",
        "grid_svm = GridSearchCV(csvm, param_grid=gridCV_svm, cv=5)\n",
        "grid_nb = GridSearchCV(nb, param_grid=gridCV_naivebyes, cv=5)\n",
        "grid_ab = GridSearchCV(ab, param_grid=gridCV_adaboost, cv=5)\n",
        "grid_gb = GridSearchCV(gb, param_grid=gridCV_gradientboost, cv=5)\n",
        "grid_mlp = GridSearchCV(mlp, param_grid=gridCV_MLP, cv=5)\n",
        "\n",
        "grid_rf.fit(dados_treino, classe_treino)\n",
        "grid_lr.fit(dados_treino, classe_treino)\n",
        "grid_svm.fit(dados_treino, classe_treino)\n",
        "grid_nb.fit(dados_treino, classe_treino)\n",
        "grid_ab.fit(dados_treino, classe_treino)\n",
        "grid_gb.fit(dados_treino, classe_treino)\n",
        "grid_mlp.fit(dados_treino, classe_treino)\n",
        "\n",
        "print(grid_rf.best_estimator_)\n",
        "print(grid_lr.best_estimator_)\n",
        "print(grid_svm.best_estimator_)\n",
        "print(grid_nb.best_estimator_)\n",
        "print(grid_ab.best_estimator_)\n",
        "print(grid_gb.best_estimator_)\n",
        "print(grid_mlp.best_estimator_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owmwUgkuk3sl"
      },
      "source": [
        "And that's it: we already know that the best tuning of the given options for each model. Now we will update the parameters of the models by those obtained above and train again the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UeuUo6p1ee6C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa88a589-5fbc-4262-9375-1b50810dd8b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuned RF accuracy: 0.673469387755102\n",
            "Tuned LR accuracy: 0.6394557823129252\n",
            "Tuned SVM accuracy: 0.5510204081632653\n",
            "Tuned Naive Bayes accuracy: 0.5986394557823129\n",
            "Tuned AdaBoost accuracy: 0.673469387755102\n",
            "Tuned GradientBoost accuracy: 0.6462585034013606\n",
            "Tuned MLP accuracy: 0.5850340136054422\n"
          ]
        }
      ],
      "source": [
        "rf_tunado = RandomForestClassifier(max_depth=5, max_features='log2', max_leaf_nodes=9, n_estimators=5)\n",
        "lr_tunado = LogisticRegression(C=0.1, max_iter=100000)\n",
        "svm_tunado = svm.LinearSVC(C=100, max_iter=100000)\n",
        "nb_tunado = GaussianNB(var_smoothing=8.111308307896856e-09)\n",
        "ab_tunado = AdaBoostClassifier(algorithm='SAMME', n_estimators=1)\n",
        "gb_tunado = GradientBoostingClassifier(learning_rate=0.01, max_depth=5, n_estimators=200)\n",
        "mlp_tunado = MLPClassifier(activation='tanh', hidden_layer_sizes=(100, 150, 30), learning_rate='adaptive', max_iter=100000, solver='lbfgs')\n",
        "\n",
        "rf_tunado.fit(dados_treino, classe_treino)\n",
        "lr_tunado.fit(dados_treino, classe_treino)\n",
        "svm_tunado.fit(dados_treino, classe_treino)\n",
        "nb_tunado.fit(dados_treino, classe_treino)\n",
        "ab_tunado.fit(dados_treino, classe_treino)\n",
        "gb_tunado.fit(dados_treino, classe_treino)\n",
        "mlp_tunado.fit(dados_treino, classe_treino)\n",
        "\n",
        "predicoes_tunadas_rf = rf_tunado.predict(dados_teste)\n",
        "predicoes_tunadas_lr = lr_tunado.predict(dados_teste)\n",
        "predicoes_tunadas_svm = svm_tunado.predict(dados_teste)\n",
        "predicoes_tunadas_nb = nb_tunado.predict(dados_teste)\n",
        "predicoes_tunadas_ab = ab_tunado.predict(dados_teste)\n",
        "predicoes_tunadas_gb = gb_tunado.predict(dados_teste)\n",
        "predicoes_tunadas_MLP = mlp_tunado.predict(dados_teste)\n",
        "\n",
        "print(\"Tuned RF accuracy:\", metrics.accuracy_score(classe_teste, predicoes_tunadas_rf))\n",
        "print(\"Tuned LR accuracy:\", metrics.accuracy_score(classe_teste, predicoes_tunadas_lr))\n",
        "print(\"Tuned SVM accuracy:\", metrics.accuracy_score(classe_teste, predicoes_tunadas_svm))\n",
        "print(\"Tuned Naive Bayes accuracy:\", metrics.accuracy_score(classe_teste, predicoes_tunadas_nb))\n",
        "print(\"Tuned AdaBoost accuracy:\", metrics.accuracy_score(classe_teste, predicoes_tunadas_ab))\n",
        "print(\"Tuned GradientBoost accuracy:\", metrics.accuracy_score(classe_teste, predicoes_tunadas_gb))\n",
        "print(\"Tuned MLP accuracy:\", metrics.accuracy_score(classe_teste, predicoes_tunadas_MLP))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCXHmy5RlwGB"
      },
      "source": [
        "With the changes in the hyperparameters tunings, we can see that the trained models, in a general way, had they accuracy increased. Maybe if we had more data (more instances in the dataset), we could get better results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyTVp9cSqZz6"
      },
      "source": [
        "Let's take a look to another metrics, like *Precision*, *Recall* and *F1-Score*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZgli6yJqi0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91eeb260-48d9-4d40-eda7-88bd9ba5dd8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report (Random Forest): \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.76      0.88      0.82        86\n",
            "         2.0       0.56      0.52      0.54        44\n",
            "         3.0       0.17      0.08      0.11        13\n",
            "         4.0       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.68       147\n",
            "   macro avg       0.37      0.37      0.37       147\n",
            "weighted avg       0.63      0.68      0.65       147\n",
            "\n",
            "Classification report (Logistic Regression): \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.72      0.88      0.79        86\n",
            "         2.0       0.49      0.45      0.47        44\n",
            "         3.0       0.00      0.00      0.00        13\n",
            "         4.0       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.65       147\n",
            "   macro avg       0.30      0.33      0.32       147\n",
            "weighted avg       0.57      0.65      0.60       147\n",
            "\n",
            "Classification report (SVM): \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.72      0.84      0.77        86\n",
            "         2.0       0.58      0.43      0.49        44\n",
            "         3.0       0.15      0.15      0.15        13\n",
            "         4.0       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.63       147\n",
            "   macro avg       0.36      0.36      0.36       147\n",
            "weighted avg       0.61      0.63      0.61       147\n",
            "\n",
            "Classification report (Naive Bayes): \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.71      0.91      0.80        86\n",
            "         2.0       0.57      0.09      0.16        44\n",
            "         3.0       0.20      0.46      0.28        13\n",
            "         4.0       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.60       147\n",
            "   macro avg       0.37      0.36      0.31       147\n",
            "weighted avg       0.60      0.60      0.54       147\n",
            "\n",
            "Classification report (AdaBoost): \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.76      0.84      0.80        86\n",
            "         2.0       0.62      0.48      0.54        44\n",
            "         3.0       0.11      0.08      0.09        13\n",
            "         4.0       0.22      0.50      0.31         4\n",
            "\n",
            "    accuracy                           0.65       147\n",
            "   macro avg       0.43      0.47      0.43       147\n",
            "weighted avg       0.64      0.65      0.64       147\n",
            "\n",
            "Classification report (GradientBoost): \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.74      0.84      0.79        86\n",
            "         2.0       0.56      0.50      0.53        44\n",
            "         3.0       0.29      0.15      0.20        13\n",
            "         4.0       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.65       147\n",
            "   macro avg       0.40      0.37      0.38       147\n",
            "weighted avg       0.63      0.65      0.64       147\n",
            "\n",
            "Classification report (MLP): \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.59      1.00      0.74        86\n",
            "         2.0       0.00      0.00      0.00        44\n",
            "         3.0       0.00      0.00      0.00        13\n",
            "         4.0       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.59       147\n",
            "   macro avg       0.15      0.25      0.18       147\n",
            "weighted avg       0.34      0.59      0.43       147\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Classification report (Random Forest): \\n\", classification_report(classe_teste, predicoes_rf))\n",
        "print(\"Classification report (Logistic Regression): \\n\", classification_report(classe_teste, predicoes_lr))\n",
        "print(\"Classification report (SVM): \\n\", classification_report(classe_teste, predicoes_svm))\n",
        "print(\"Classification report (Naive Bayes): \\n\", classification_report(classe_teste, predicoes_nb))\n",
        "print(\"Classification report (AdaBoost): \\n\", classification_report(classe_teste, predicoes_ab))\n",
        "print(\"Classification report (GradientBoost): \\n\", classification_report(classe_teste, predicoes_gb))\n",
        "print(\"Classification report (MLP): \\n\", classification_report(classe_teste, predicoes_mlp))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But taking a look to Precision and Recall of the minority classes, they seem to be not so good. It's time to solve the imbalance problem and take a look again."
      ],
      "metadata": {
        "id": "62K5Z7jOzk83"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpd4GN6tnJCc"
      },
      "source": [
        "Let's use the SMOTE library to handle with the imbalance problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbVmsXt9nOfX"
      },
      "outputs": [],
      "source": [
        "sm = SMOTE()\n",
        "\n",
        "dados_treino_balanced, classe_treino_balanced = sm.fit_resample(dados_treino, classe_treino)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxDL2MxFxkwJ"
      },
      "source": [
        "Now we oversampled the `dados_treino` partition - based on majority class - using the SMOTE algorithm."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dados_treino_balanced.describe()"
      ],
      "metadata": {
        "id": "sumCccFLrZTH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "50ff1055-9282-4e5b-fa0b-740fc1a2c6a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       COMPRIMENTO    TEMP_MIN    TEMP_MAX    TEMP_MED     TEMP_PO  \\\n",
              "count   808.000000  808.000000  808.000000  808.000000  808.000000   \n",
              "mean      5.157799    5.390419   33.166885   17.740527   13.060639   \n",
              "std       0.320242    3.560996    5.653590    2.675661    2.150968   \n",
              "min       3.900000    1.900000   18.100000   11.760000    6.380000   \n",
              "25%       5.140409    2.188991   28.614028   15.950000   11.685605   \n",
              "50%       5.200000    4.252553   34.400000   17.694773   13.122064   \n",
              "75%       5.200000    7.948627   38.442242   19.505458   14.400320   \n",
              "max       6.000000   24.000000   39.400000   26.930000   23.340000   \n",
              "\n",
              "       PRECIPITACAO     PATM_MED      UR_MIN      UR_MED   VENTO_MED  ...  \\\n",
              "count    808.000000   808.000000  808.000000  808.000000  808.000000  ...   \n",
              "mean     309.476252  1015.793976   26.814299   75.668090    3.107150  ...   \n",
              "std      194.274154     2.286034    8.301521    3.212642    0.358890  ...   \n",
              "min        0.000000  1005.890000   21.000000   64.360000    1.430000  ...   \n",
              "25%      133.247506  1014.667855   21.000000   73.807754    2.945467  ...   \n",
              "50%      324.716084  1015.960000   21.281516   76.016305    3.190425  ...   \n",
              "75%      487.082098  1016.774617   32.000000   77.676192    3.275236  ...   \n",
              "max     1156.000000  1026.700000   70.000000   84.670000    4.630000  ...   \n",
              "\n",
              "       DIAMETRO_12 a 20  DIAMETRO_14 a 22  DIAMETRO_20 a 30  DIAMETRO_22 a 32  \\\n",
              "count        808.000000        808.000000        808.000000        808.000000   \n",
              "mean           0.319307          0.019802          0.214109          0.007426   \n",
              "std            0.466497          0.139406          0.410457          0.085905   \n",
              "min            0.000000          0.000000          0.000000          0.000000   \n",
              "25%            0.000000          0.000000          0.000000          0.000000   \n",
              "50%            0.000000          0.000000          0.000000          0.000000   \n",
              "75%            1.000000          0.000000          0.000000          0.000000   \n",
              "max            1.000000          1.000000          1.000000          1.000000   \n",
              "\n",
              "       DIAMETRO_30 a 40  DIAMETRO_32 a 42  DIAMETRO_40 a 60  DIAMETRO_8 a 12  \\\n",
              "count        808.000000        808.000000        808.000000       808.000000   \n",
              "mean           0.064356          0.002475          0.013614         0.001238   \n",
              "std            0.245539          0.049721          0.115953         0.035180   \n",
              "min            0.000000          0.000000          0.000000         0.000000   \n",
              "25%            0.000000          0.000000          0.000000         0.000000   \n",
              "50%            0.000000          0.000000          0.000000         0.000000   \n",
              "75%            0.000000          0.000000          0.000000         0.000000   \n",
              "max            1.000000          1.000000          1.000000         1.000000   \n",
              "\n",
              "       DIAMETRO_8 a 14  DIAMETRO_8 a 20  \n",
              "count       808.000000       808.000000  \n",
              "mean          0.007426         0.022277  \n",
              "std           0.085905         0.147675  \n",
              "min           0.000000         0.000000  \n",
              "25%           0.000000         0.000000  \n",
              "50%           0.000000         0.000000  \n",
              "75%           0.000000         0.000000  \n",
              "max           1.000000         1.000000  \n",
              "\n",
              "[8 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d50f59f1-bc98-4b1c-91e6-99f043017d50\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>COMPRIMENTO</th>\n",
              "      <th>TEMP_MIN</th>\n",
              "      <th>TEMP_MAX</th>\n",
              "      <th>TEMP_MED</th>\n",
              "      <th>TEMP_PO</th>\n",
              "      <th>PRECIPITACAO</th>\n",
              "      <th>PATM_MED</th>\n",
              "      <th>UR_MIN</th>\n",
              "      <th>UR_MED</th>\n",
              "      <th>VENTO_MED</th>\n",
              "      <th>...</th>\n",
              "      <th>DIAMETRO_12 a 20</th>\n",
              "      <th>DIAMETRO_14 a 22</th>\n",
              "      <th>DIAMETRO_20 a 30</th>\n",
              "      <th>DIAMETRO_22 a 32</th>\n",
              "      <th>DIAMETRO_30 a 40</th>\n",
              "      <th>DIAMETRO_32 a 42</th>\n",
              "      <th>DIAMETRO_40 a 60</th>\n",
              "      <th>DIAMETRO_8 a 12</th>\n",
              "      <th>DIAMETRO_8 a 14</th>\n",
              "      <th>DIAMETRO_8 a 20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>808.000000</td>\n",
              "      <td>808.000000</td>\n",
              "      <td>808.000000</td>\n",
              "      <td>808.000000</td>\n",
              "      <td>808.000000</td>\n",
              "      <td>808.000000</td>\n",
              "      <td>808.000000</td>\n",
              "      <td>808.000000</td>\n",
              "      <td>808.000000</td>\n",
              "      <td>808.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>808.000000</td>\n",
              "      <td>808.000000</td>\n",
              "      <td>808.000000</td>\n",
              "      <td>808.000000</td>\n",
              "      <td>808.000000</td>\n",
              "      <td>808.000000</td>\n",
              "      <td>808.000000</td>\n",
              "      <td>808.000000</td>\n",
              "      <td>808.000000</td>\n",
              "      <td>808.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.157799</td>\n",
              "      <td>5.390419</td>\n",
              "      <td>33.166885</td>\n",
              "      <td>17.740527</td>\n",
              "      <td>13.060639</td>\n",
              "      <td>309.476252</td>\n",
              "      <td>1015.793976</td>\n",
              "      <td>26.814299</td>\n",
              "      <td>75.668090</td>\n",
              "      <td>3.107150</td>\n",
              "      <td>...</td>\n",
              "      <td>0.319307</td>\n",
              "      <td>0.019802</td>\n",
              "      <td>0.214109</td>\n",
              "      <td>0.007426</td>\n",
              "      <td>0.064356</td>\n",
              "      <td>0.002475</td>\n",
              "      <td>0.013614</td>\n",
              "      <td>0.001238</td>\n",
              "      <td>0.007426</td>\n",
              "      <td>0.022277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.320242</td>\n",
              "      <td>3.560996</td>\n",
              "      <td>5.653590</td>\n",
              "      <td>2.675661</td>\n",
              "      <td>2.150968</td>\n",
              "      <td>194.274154</td>\n",
              "      <td>2.286034</td>\n",
              "      <td>8.301521</td>\n",
              "      <td>3.212642</td>\n",
              "      <td>0.358890</td>\n",
              "      <td>...</td>\n",
              "      <td>0.466497</td>\n",
              "      <td>0.139406</td>\n",
              "      <td>0.410457</td>\n",
              "      <td>0.085905</td>\n",
              "      <td>0.245539</td>\n",
              "      <td>0.049721</td>\n",
              "      <td>0.115953</td>\n",
              "      <td>0.035180</td>\n",
              "      <td>0.085905</td>\n",
              "      <td>0.147675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>3.900000</td>\n",
              "      <td>1.900000</td>\n",
              "      <td>18.100000</td>\n",
              "      <td>11.760000</td>\n",
              "      <td>6.380000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1005.890000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>64.360000</td>\n",
              "      <td>1.430000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.140409</td>\n",
              "      <td>2.188991</td>\n",
              "      <td>28.614028</td>\n",
              "      <td>15.950000</td>\n",
              "      <td>11.685605</td>\n",
              "      <td>133.247506</td>\n",
              "      <td>1014.667855</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>73.807754</td>\n",
              "      <td>2.945467</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.200000</td>\n",
              "      <td>4.252553</td>\n",
              "      <td>34.400000</td>\n",
              "      <td>17.694773</td>\n",
              "      <td>13.122064</td>\n",
              "      <td>324.716084</td>\n",
              "      <td>1015.960000</td>\n",
              "      <td>21.281516</td>\n",
              "      <td>76.016305</td>\n",
              "      <td>3.190425</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.200000</td>\n",
              "      <td>7.948627</td>\n",
              "      <td>38.442242</td>\n",
              "      <td>19.505458</td>\n",
              "      <td>14.400320</td>\n",
              "      <td>487.082098</td>\n",
              "      <td>1016.774617</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>77.676192</td>\n",
              "      <td>3.275236</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>39.400000</td>\n",
              "      <td>26.930000</td>\n",
              "      <td>23.340000</td>\n",
              "      <td>1156.000000</td>\n",
              "      <td>1026.700000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>84.670000</td>\n",
              "      <td>4.630000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d50f59f1-bc98-4b1c-91e6-99f043017d50')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d50f59f1-bc98-4b1c-91e6-99f043017d50 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d50f59f1-bc98-4b1c-91e6-99f043017d50');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is to train our classifiers again, now with the new balanced data."
      ],
      "metadata": {
        "id": "ceRu4IQRDXKe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxU3uJ4CnrEo"
      },
      "outputs": [],
      "source": [
        "rf_tunado.fit(dados_treino_balanced, classe_treino_balanced)\n",
        "lr_tunado.fit(dados_treino_balanced, classe_treino_balanced)\n",
        "svm_tunado.fit(dados_treino_balanced, classe_treino_balanced)\n",
        "nb_tunado.fit(dados_treino_balanced, classe_treino_balanced)\n",
        "ab_tunado.fit(dados_treino_balanced, classe_treino_balanced)\n",
        "gb_tunado.fit(dados_treino_balanced, classe_treino_balanced)\n",
        "mlp_tunado.fit(dados_treino_balanced, classe_treino_balanced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkWHQEdVyA91"
      },
      "source": [
        "At this point, our classifiers are already trained with our balanced data. It's time to get its predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHk6ubGzn0lB"
      },
      "outputs": [],
      "source": [
        "predicoes_rf_balanced = rf_tunado.predict(dados_teste)\n",
        "predicoes_lr_balanced = lr_tunado.predict(dados_teste)\n",
        "predicoes_svm_balanced = svm_tunado.predict(dados_teste)\n",
        "predicoes_nb_balanced = nb_tunado.predict(dados_teste)\n",
        "predicoes_ab_balanced = ab_tunado.predict(dados_teste)\n",
        "predicoes_gb_balanced = gb_tunado.predict(dados_teste)\n",
        "predicoes_mlp_balanced = mlp_tunado.predict(dados_teste)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP_SD-W1yNlV"
      },
      "source": [
        "Having the predictions, let's take a look at the confusion matrixes using the new balanced data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcK79CQbn96c",
        "outputId": "12a1257a-3833-44c0-d0ac-9e092dc51d5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix of RF (after balancing the data): \n",
            " [[74  4  4  4]\n",
            " [18 22  4  0]\n",
            " [ 4  5  3  1]\n",
            " [ 1  1  1  1]]\n",
            "Confusion matrix of LR (after balancing the data): \n",
            " [[61 13  3  9]\n",
            " [17 12  8  7]\n",
            " [ 5  4  2  2]\n",
            " [ 1  0  0  3]]\n",
            "Confusion matrix of SVM (after balancing the data): \n",
            " [[ 1 85  0  0]\n",
            " [ 0 44  0  0]\n",
            " [ 0 13  0  0]\n",
            " [ 0  4  0  0]]\n",
            "Confusion matrix of Naive Bayes (after balancing the data): \n",
            " [[24  7 14 41]\n",
            " [ 6  3 14 21]\n",
            " [ 2  2  3  6]\n",
            " [ 0  0  0  4]]\n",
            "Confusion matrix of AdaBoost (after balancing the data): \n",
            " [[57  0 29  0]\n",
            " [ 9  0 35  0]\n",
            " [ 4  0  9  0]\n",
            " [ 1  0  3  0]]\n",
            "Confusion matrix of Gradient Boost (after balancing the data): \n",
            " [[67 13  3  3]\n",
            " [21 21  2  0]\n",
            " [ 4  5  3  1]\n",
            " [ 1  1  1  1]]\n",
            "Confusion matrix of MLP (after balancing the data): \n",
            " [[71  0  0 15]\n",
            " [23  0  0 21]\n",
            " [ 8  0  0  5]\n",
            " [ 1  0  0  3]]\n"
          ]
        }
      ],
      "source": [
        "cm_rf_balanced = confusion_matrix(classe_teste, predicoes_rf_balanced)\n",
        "cm_lr_balanced = confusion_matrix(classe_teste, predicoes_lr_balanced)\n",
        "cm_svm_balanced = confusion_matrix(classe_teste, predicoes_svm_balanced)\n",
        "cm_nb_balanced = confusion_matrix(classe_teste, predicoes_nb_balanced)\n",
        "cm_ab_balanced = confusion_matrix(classe_teste, predicoes_ab_balanced)\n",
        "cm_gb_balanced = confusion_matrix(classe_teste, predicoes_gb_balanced)\n",
        "cm_mlp_balanced = confusion_matrix(classe_teste, predicoes_mlp_balanced)\n",
        "\n",
        "print(\"Confusion matrix of RF (after balancing the data): \\n\", cm_rf_balanced)\n",
        "print(\"Confusion matrix of LR (after balancing the data): \\n\", cm_lr_balanced)\n",
        "print(\"Confusion matrix of SVM (after balancing the data): \\n\", cm_svm_balanced)\n",
        "print(\"Confusion matrix of Naive Bayes (after balancing the data): \\n\", cm_nb_balanced)\n",
        "print(\"Confusion matrix of AdaBoost (after balancing the data): \\n\", cm_ab_balanced)\n",
        "print(\"Confusion matrix of Gradient Boost (after balancing the data): \\n\", cm_gb_balanced)\n",
        "print(\"Confusion matrix of MLP (after balancing the data): \\n\", cm_mlp_balanced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff7C92kGybhu"
      },
      "source": [
        "We can clearly see, taking a look at the confusion matrixes above, that our models are still penalizing the minority class - even after the balancing. Let's take a deeper look at the general accuracy of the new models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0G-RQB0qHm2",
        "outputId": "dbe43f0c-ec9d-4856-f22f-1ab482a7ea4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced RF accuracy: 0.6802721088435374\n",
            "Balanced LR accuracy: 0.5306122448979592\n",
            "Balanced SVM accuracy: 0.30612244897959184\n",
            "Balanced NB accuracy: 0.23129251700680273\n",
            "Balanced AB accuracy: 0.4489795918367347\n",
            "Balanced GB accuracy: 0.6258503401360545\n",
            "Balanced MLP accuracy: 0.5034013605442177\n"
          ]
        }
      ],
      "source": [
        "print(\"Balanced RF accuracy:\", metrics.accuracy_score(classe_teste, predicoes_rf_balanced))\n",
        "print(\"Balanced LR accuracy:\", metrics.accuracy_score(classe_teste, predicoes_lr_balanced))\n",
        "print(\"Balanced SVM accuracy:\", metrics.accuracy_score(classe_teste, predicoes_svm_balanced))\n",
        "print(\"Balanced NB accuracy:\", metrics.accuracy_score(classe_teste, predicoes_nb_balanced))\n",
        "print(\"Balanced AB accuracy:\", metrics.accuracy_score(classe_teste, predicoes_ab_balanced))\n",
        "print(\"Balanced GB accuracy:\", metrics.accuracy_score(classe_teste, predicoes_gb_balanced))\n",
        "print(\"Balanced MLP accuracy:\", metrics.accuracy_score(classe_teste, predicoes_mlp_balanced))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's take a look at the classification reports."
      ],
      "metadata": {
        "id": "wyIMBTk1Rrrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification report (Random Forest): \\n\", classification_report(classe_teste, predicoes_rf_balanced))\n",
        "print(\"Classification report (Logistic Regression): \\n\", classification_report(classe_teste, predicoes_lr_balanced))\n",
        "print(\"Classification report (SVM): \\n\", classification_report(classe_teste, predicoes_svm_balanced))\n",
        "print(\"Classification report (Naive Bayes): \\n\", classification_report(classe_teste, predicoes_nb_balanced))\n",
        "print(\"Classification report (AdaBoost): \\n\", classification_report(classe_teste, predicoes_ab_balanced))\n",
        "print(\"Classification report (GradientBoost): \\n\", classification_report(classe_teste, predicoes_gb_balanced))\n",
        "print(\"Classification report (MLP): \\n\", classification_report(classe_teste, predicoes_mlp_balanced))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ1zXGMnRxB6",
        "outputId": "7cf508ce-c55a-4070-92d9-c9c9e91f43ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report (Random Forest): \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.76      0.86      0.81        86\n",
            "         2.0       0.69      0.50      0.58        44\n",
            "         3.0       0.25      0.23      0.24        13\n",
            "         4.0       0.17      0.25      0.20         4\n",
            "\n",
            "    accuracy                           0.68       147\n",
            "   macro avg       0.47      0.46      0.46       147\n",
            "weighted avg       0.68      0.68      0.67       147\n",
            "\n",
            "Classification report (Logistic Regression): \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.73      0.71      0.72        86\n",
            "         2.0       0.41      0.27      0.33        44\n",
            "         3.0       0.15      0.15      0.15        13\n",
            "         4.0       0.14      0.75      0.24         4\n",
            "\n",
            "    accuracy                           0.53       147\n",
            "   macro avg       0.36      0.47      0.36       147\n",
            "weighted avg       0.57      0.53      0.54       147\n",
            "\n",
            "Classification report (SVM): \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         1.0       1.00      0.01      0.02        86\n",
            "         2.0       0.30      1.00      0.46        44\n",
            "         3.0       0.00      0.00      0.00        13\n",
            "         4.0       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.31       147\n",
            "   macro avg       0.33      0.25      0.12       147\n",
            "weighted avg       0.68      0.31      0.15       147\n",
            "\n",
            "Classification report (Naive Bayes): \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.75      0.28      0.41        86\n",
            "         2.0       0.25      0.07      0.11        44\n",
            "         3.0       0.10      0.23      0.14        13\n",
            "         4.0       0.06      1.00      0.11         4\n",
            "\n",
            "    accuracy                           0.23       147\n",
            "   macro avg       0.29      0.39      0.19       147\n",
            "weighted avg       0.52      0.23      0.28       147\n",
            "\n",
            "Classification report (AdaBoost): \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.80      0.66      0.73        86\n",
            "         2.0       0.00      0.00      0.00        44\n",
            "         3.0       0.12      0.69      0.20        13\n",
            "         4.0       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.45       147\n",
            "   macro avg       0.23      0.34      0.23       147\n",
            "weighted avg       0.48      0.45      0.44       147\n",
            "\n",
            "Classification report (GradientBoost): \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.72      0.78      0.75        86\n",
            "         2.0       0.53      0.48      0.50        44\n",
            "         3.0       0.33      0.23      0.27        13\n",
            "         4.0       0.20      0.25      0.22         4\n",
            "\n",
            "    accuracy                           0.63       147\n",
            "   macro avg       0.44      0.43      0.44       147\n",
            "weighted avg       0.61      0.63      0.62       147\n",
            "\n",
            "Classification report (MLP): \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.69      0.83      0.75        86\n",
            "         2.0       0.00      0.00      0.00        44\n",
            "         3.0       0.00      0.00      0.00        13\n",
            "         4.0       0.07      0.75      0.12         4\n",
            "\n",
            "    accuracy                           0.50       147\n",
            "   macro avg       0.19      0.39      0.22       147\n",
            "weighted avg       0.41      0.50      0.44       147\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taking a look at the classification reports above, we can say that the class imbalance impacts negatively, given the training of developed models above."
      ],
      "metadata": {
        "id": "I3-lLW3_e2rO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's apply a statistic test, called \"Align Fridman\", ignoring the balancing of the classes. At first, we choose the variables we want to compare, model by model, and put them into an array.\n",
        "\n",
        "We will choose, in this development: accuracy, precision, recall, and F1-score.\n",
        "\n",
        "At first, we will save our developed classification models inside an array.\n",
        "\n",
        "*   Accuracy is how close a given set of predictions are to their true value;\n",
        "*   Precision is the ability of the model not to label as positive a sample that is negative;\n",
        "*   Recall is the ability of the model to find all the positive samples;\n",
        "*   F1 is the harmonic mean between precision and recall.\n",
        "\n",
        "```\n",
        "PRECISION = TP / (TP + FP)\n",
        "```\n",
        "```\n",
        "RECALL = TP / (TP + FN)\n",
        "```\n",
        "```\n",
        "F1 = 2 * (PRECISION * RECALL) / (PRECISION + RECALL)\n",
        "```"
      ],
      "metadata": {
        "id": "ztOcvPs_fY7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelos = [\n",
        "    rf_tunado,\n",
        "    lr_tunado,\n",
        "    svm_tunado,\n",
        "    nb_tunado,\n",
        "    ab_tunado,\n",
        "    gb_tunado,\n",
        "    mlp_tunado\n",
        "]"
      ],
      "metadata": {
        "id": "LU8-5zRwgoYt"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After that, we need to create another array to save the results of the metrics for each developed model."
      ],
      "metadata": {
        "id": "XLgrftiuscB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resultado = []"
      ],
      "metadata": {
        "id": "OcXohWYVsmmf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we are ready to save it all in our array. Let's go through the developed models, checking the results for each metric and storing them in our array.\n",
        "\n",
        "Note that are some possible values to the *average* parameter in some functions below.\n",
        "\n",
        "Here are some brief descriptions:\n",
        "\n",
        "* \"micro\": calculates the metric globally, considering all the classes. It's usually recommended to problems that deals with imbalanced classes;\n",
        "* \"macro\": calculates the metric for each class, ingoring the balancing of the classes. It's recommended when equal weight is wanted to all classes;\n",
        "* \"weighted\": calculates the weighted average for each class, given the number of samples in each class. It's recommended when the dataset is imbalanced and more weight to the minority class is wanted.\n",
        "\n",
        "So, we will use the *weighted* avarage, trying to deal with our imbalanced problem."
      ],
      "metadata": {
        "id": "DPluMVGYsp9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for indice, modelo in enumerate(modelos):\n",
        "    \n",
        "    modelo.fit(dados_treino, classe_treino)\n",
        "    predicoes = modelo.predict(dados_teste)\n",
        "    \n",
        "    acuracia = accuracy_score(classe_teste, predicoes)\n",
        "    precisao = precision_score(classe_teste, predicoes, average='weighted')\n",
        "    revocacao = recall_score(classe_teste, predicoes, average='weighted')\n",
        "    f1 = f1_score(classe_teste, predicoes, average='weighted')\n",
        "\n",
        "    resultados_preliminares = {\n",
        "        'MODELO': str(modelo),\n",
        "        'ACURACIA': acuracia,\n",
        "        'PRECISAO': precisao,\n",
        "        'REVOCACAO': revocacao,\n",
        "        'F1': f1\n",
        "    }\n",
        "\n",
        "    resultado.append(resultados_preliminares)"
      ],
      "metadata": {
        "id": "cenz61WEs7lb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultado"
      ],
      "metadata": {
        "id": "BMWsx8d6MP6F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9454ba6-a408-4a9e-86b6-c30170cdf9e1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'MODELO': \"RandomForestClassifier(max_depth=5, max_features='log2', max_leaf_nodes=9,\\n                       n_estimators=5)\",\n",
              "  'ACURACIA': 0.6802721088435374,\n",
              "  'PRECISAO': 0.6276884491170206,\n",
              "  'REVOCACAO': 0.6802721088435374,\n",
              "  'F1': 0.6475433416609888},\n",
              " {'MODELO': 'LogisticRegression(C=0.1, max_iter=100000)',\n",
              "  'ACURACIA': 0.6394557823129252,\n",
              "  'PRECISAO': 0.549838168885788,\n",
              "  'REVOCACAO': 0.6394557823129252,\n",
              "  'F1': 0.5882025894446712},\n",
              " {'MODELO': 'LinearSVC(C=100, max_iter=100000)',\n",
              "  'ACURACIA': 0.3197278911564626,\n",
              "  'PRECISAO': 0.6060900550696469,\n",
              "  'REVOCACAO': 0.3197278911564626,\n",
              "  'F1': 0.4172335600907029},\n",
              " {'MODELO': 'GaussianNB(var_smoothing=8.111308307896856e-09)',\n",
              "  'ACURACIA': 0.5986394557823129,\n",
              "  'PRECISAO': 0.5906198504246419,\n",
              "  'REVOCACAO': 0.5986394557823129,\n",
              "  'F1': 0.5301020643921356},\n",
              " {'MODELO': \"AdaBoostClassifier(algorithm='SAMME', n_estimators=1)\",\n",
              "  'ACURACIA': 0.673469387755102,\n",
              "  'PRECISAO': 0.6005947943207793,\n",
              "  'REVOCACAO': 0.673469387755102,\n",
              "  'F1': 0.6346588119783996},\n",
              " {'MODELO': 'GradientBoostingClassifier(learning_rate=0.01, max_depth=5, n_estimators=200)',\n",
              "  'ACURACIA': 0.6462585034013606,\n",
              "  'PRECISAO': 0.6167278720823642,\n",
              "  'REVOCACAO': 0.6462585034013606,\n",
              "  'F1': 0.6290968252596462},\n",
              " {'MODELO': \"MLPClassifier(activation='tanh', hidden_layer_sizes=(100, 150, 30),\\n              learning_rate='adaptive', max_iter=100000, solver='lbfgs')\",\n",
              "  'ACURACIA': 0.5850340136054422,\n",
              "  'PRECISAO': 0.3422647970752927,\n",
              "  'REVOCACAO': 0.5850340136054422,\n",
              "  'F1': 0.43187060231818053}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point, we are ready to start the evaluation stage of our models. We have to decide which one is better to solve the prediction of the moisture content variation on wood problem.\n",
        "\n",
        "We will start comparing the developed models, looking for statistical differences between them. For this, the most known is the Align-Friedman test, a statistical technique also used - among many other purposes - to compare the performance of machine learning models.\n",
        "\n",
        "With the Align-Friedman test, we can interpret the p value to determine whether there is a statistically significant difference between the models developed to solve the referred problem.\n",
        "\n",
        "The Align-Friedman test uses the following null and alternative hypotheses:\n",
        "\n",
        "* The null hypothesis (H0): the models performance are equal;\n",
        "* The alternative hypothesis (Ha): at least one model performance is different from the others.\n",
        "\n",
        "If the p-value is less than a predetermined significance level (usually 5%, or 0.05), the null hypothesis (that the models are equal, by they performance) can be rejected, and thus we can conclude that at least one of the models that was developed is significantly better than the others. Otherwise, the null hypothesis cannot be rejected - this means concluding that all models performed similarly. The statistic generated by the test is a measure of how different the compared models are in terms of their average overall rating across all evaluation metrics."
      ],
      "metadata": {
        "id": "CebbALYkuoHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_resultado = pandas.DataFrame(resultado)\n",
        "\n",
        "acuracia = df_resultado['ACURACIA'].values\n",
        "precisao = df_resultado['PRECISAO'].values\n",
        "revocacao = df_resultado['REVOCACAO'].values\n",
        "f1 = df_resultado['F1'].values\n",
        "\n",
        "f_valor, p_valor = friedmanchisquare(acuracia, precisao, revocacao, f1)\n",
        "\n",
        "print(\"F-value of Align-Friedman: \", f_valor)\n",
        "print(\"p-value of Align-Friedman: \", p_valor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6JIiLQbyTcV",
        "outputId": "67233804-8964-48d2-a616-a21bed065a80"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-value of Align-Friedman:  9.95238095238095\n",
            "p-value of Align-Friedman:  0.018975282112339117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see above, a low p-value, as is the case in question (0.01), indicates that it is highly unlikely that the observed result occurred by chance, reinforcing the evidence against the null hypothesis and in favor of the alternative hypothesis. Therefore, we can reject the null hypothesis and conclude that there is a significant difference between the tested models.\n",
        "\n",
        "Now it's time to find the best model, based on the four metrics (accuracy, precision, recall and F1-score).\n",
        "\n",
        "The easier way to select the best model based on various metrics is to use the *model ranking* technique - according to overall performance. One possible approach is to calculate the aggregate score (or overall score) for each model, which is a weighted average of the individual metrics. After that, sort the models in descending order of aggregate score and select the best performing model.\n",
        "\n",
        "About precision and recall, we used the weighted average. So, we will use the arithmetic mean with equal weights for all metrics."
      ],
      "metadata": {
        "id": "Qqxua3u0d5S5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score_agregado = (acuracia + precisao + revocacao + f1) / 4\n",
        "\n",
        "for result in resultado:\n",
        "    result['SCORE_AGREGADO'] = (result['ACURACIA'] + result['PRECISAO'] + result['REVOCACAO'] + result['F1']) / 4\n",
        "\n",
        "resultados_ordenados = sorted(resultado, key=lambda x: x['SCORE_AGREGADO'], reverse=True)\n",
        "\n",
        "print(\"O melhor modelo é: \", resultados_ordenados[0]['MODELO'])\n",
        "print(\"O score agregado do melhor modelo é de: \", resultados_ordenados[0]['SCORE_AGREGADO'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fkd6zhOHx3GM",
        "outputId": "c0b1c24c-36c7-4779-a46e-c470f8d8e12f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O melhor modelo é:  RandomForestClassifier(max_depth=5, max_features='log2', max_leaf_nodes=9,\n",
            "                       n_estimators=5)\n",
            "O score agregado do melhor modelo é de:  0.6589440021162711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will apply the Bonferroni-Dunn test. To do this, we will sort the models by the aggregated score and, after that, we will create a dataframe based on it."
      ],
      "metadata": {
        "id": "sIphF1KQIlsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_ordenados = sorted(resultado, key=lambda x: x['SCORE_AGREGADO'], reverse=True)\n",
        "\n",
        "df = pandas.DataFrame(resultados_ordenados)"
      ],
      "metadata": {
        "id": "iGQqgRjJM9u9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After that, the Dunn's test is performed. Finally, the best model is identified from the significant differences obtained by Dunn's test."
      ],
      "metadata": {
        "id": "96VPVAbmNAcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# executar o teste de Dunn\n",
        "dunn_result = sp.posthoc_dunn(df, val_col='SCORE_AGREGADO', group_col='MODELO', p_adjust='bonferroni')\n",
        "\n",
        "# obter as diferenças significativas entre os modelos com um nível de significância de 0.05\n",
        "diferencas_significativas = dunn_result < 0.05\n",
        "\n",
        "# identificar o melhor modelo com base nas diferenças significativas\n",
        "melhores_modelos = diferencas_significativas.sum().sort_values().index[0]\n",
        "\n",
        "print('O melhor modelo é: ', melhores_modelos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shalT76BykOG",
        "outputId": "6c45e9c2-db85-4b02-b092-7e722859aa72"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O melhor modelo é:  AdaBoostClassifier(algorithm='SAMME', n_estimators=1)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}